# ETL Northwind Data Warehouse with Apache Airflow, Python, and PostgreSQL

## Description
This project demonstrates the implementation of an ETL pipeline for the Northwind Data Warehouse. Using Apache Airflow for orchestration, Python for data processing, and PostgreSQL for data storage, the pipeline automates data extraction, transformation, and loading.

## Features
- Workflow orchestration with Apache Airflow.
- Data extraction from multiple sources (Excel, XML, Text).
- Data transformation to meet schema requirements.
- Data loading into a PostgreSQL data warehouse.

## Technologies
- **Apache Airflow**: Workflow orchestration.
- **Python**: Data extraction and transformation.
- **PostgreSQL**: Data warehouse for Northwind.

## Setup and Usage
1. Clone this repository:
   git clone https://github.com//ETL_Northwind_Airflow_Postgres.git
2. Install the required dependencies:
   pip install -r requirements.txt
3. Set up PostgreSQL and Airflow (see detailed instructions below).
